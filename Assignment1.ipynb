{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecqztSlona5J"
      },
      "source": [
        "# **Assignment 1**\n",
        "Initial exploration of graph machine learning concepts using the \"Nations\" dataset.\n",
        "\n",
        "- The TransE paper: [*Translating Embeddings for Modeling\n",
        "Multi-relational Data*](https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmLMG_TunXvN"
      },
      "source": [
        "## **Setup**\n",
        "\n",
        "Download and process the “Nations” baseline, which you can find on GitHub, e.g.: ZhenfengLei/KGDatasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "F03vFP6iD_e_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a6ad28-28c4-412b-afae-a11d8fb3b36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezjZ7J5Uo66w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch import nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JdoDAaOnMkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45eb479a-a32c-420a-ac52-bf248a9d8dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emilio or Clare? emilio\n"
          ]
        }
      ],
      "source": [
        "# Filepaths and constants\n",
        "user = input('Emilio or Clare? ')\n",
        "if user.lower() == 'emilio':\n",
        "  folder_path = '/content/drive/MyDrive/Graph ML/data/nations/'\n",
        "elif user.lower() == 'clare':\n",
        "  folder_path = '/content/drive/MyDrive/College/College Year 3/Oxford/Graph Machine Learning/data/Nations/'\n",
        "entity_filepath = folder_path + 'entity2id.txt'\n",
        "relation_filepath = folder_path + 'relation2id.txt'\n",
        "train_filepath = folder_path + 'train.txt'\n",
        "valid_filepath = folder_path + 'valid.txt'\n",
        "test_filepath = folder_path + 'test.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSxcMcK2tFhU"
      },
      "outputs": [],
      "source": [
        "# Function to reverse a dictionary (flip keys and values)\n",
        "def reverse_dict(old_dict, new_dict):\n",
        "    for k in old_dict.keys():\n",
        "        new_dict[old_dict[k]] = k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6YKaAvXojwM"
      },
      "outputs": [],
      "source": [
        "# Dictionary mappings for entity and relation IDs\n",
        "entity_2_id = {}\n",
        "id_2_entity = {}\n",
        "\n",
        "relation_2_id = {}\n",
        "id_2_relation = {}\n",
        "\n",
        "id_2_entity = pd.read_table(entity_filepath, header=None, delim_whitespace=True).to_dict()[0]\n",
        "id_2_relation = pd.read_table(relation_filepath, header=None, delim_whitespace=True).to_dict()[0]\n",
        "\n",
        "reverse_dict(id_2_entity, entity_2_id)\n",
        "reverse_dict(id_2_relation, relation_2_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE-DFAg9v-Ft"
      },
      "outputs": [],
      "source": [
        "# Define a new class for facts - encapsulate necessary functionality\n",
        "class Fact:\n",
        "    def __init__(self, head, relation, tail):\n",
        "        self.head = head\n",
        "        self.relation = relation\n",
        "        self.tail = tail\n",
        "\n",
        "    def equals_head(self, other):\n",
        "        if self.head == other.head:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def equals_tail(self, other):\n",
        "        if self.tail == other.tail:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def equals_relation(self, other):\n",
        "        if self.relation == other.relation:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.equals_head(other) and self.equals_tail(other) and self.equals_relation(other)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.head, self.relation, self.tail))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"HI\"\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.head + \" \" + self.relation + \" \" + self.tail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBurVaSQvXO2"
      },
      "outputs": [],
      "source": [
        "# Function to translate raw data into fact objects\n",
        "def get_the_facts(content):\n",
        "    list_of_facts = []\n",
        "    for triple in content:\n",
        "        list_of_facts.append(Fact(triple.split()[0], triple.split()[1], triple.split()[2]))\n",
        "    return list_of_facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r84fT0UPublL",
        "outputId": "6b6177ef-7977-4f97-a09d-ab3feba7c4e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "netherlands militaryalliance uk\n",
            "egypt intergovorgs3 usa\n",
            "jordan relbooktranslations usa\n",
            "poland timesincewar ussr\n",
            "uk negativebehavior ussr\n",
            "poland relintergovorgs uk\n",
            "usa weightedunvote india\n",
            "china accusation india\n",
            "uk unweightedunvote egypt\n",
            "poland embassy netherlands\n",
            "\n",
            "egypt intergovorgs3 usa\n",
            "jordan relbooktranslations usa\n",
            "True\n",
            "True\n",
            "False\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Read in facts from train set\n",
        "train_file = open(train_filepath, \"r\")\n",
        "train_content = train_file.readlines()\n",
        "train_data = get_the_facts(train_content)\n",
        "\n",
        "# Checking format of facts\n",
        "for t in train_data[0:10]:\n",
        "  print(t)\n",
        "print()\n",
        "\n",
        "# Misc testing to ensure everything is set up correctly\n",
        "print(train_data[1])\n",
        "print(train_data[2])\n",
        "print(train_data[1].equals_head(train_data[1]))\n",
        "print(train_data[1].equals_tail(train_data[2]))\n",
        "print(train_data[1].equals_relation(train_data[2]))\n",
        "print(train_data[1] == train_data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esksqnd8zZNV"
      },
      "outputs": [],
      "source": [
        "# Read in validation and test facts\n",
        "valid_file = open(valid_filepath, \"r\")\n",
        "valid_content = valid_file.readlines()\n",
        "valid_data = get_the_facts(valid_content)\n",
        "\n",
        "test_file = open(test_filepath, \"r\")\n",
        "test_content = test_file.readlines()\n",
        "test_data = get_the_facts(test_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDJaBxlqn8JX"
      },
      "source": [
        "## **Question 1a**\n",
        "\n",
        "Compute the number of entities, relations, and facts, and compare with the reported numbers (sanity checks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHlxo6q5n7qm",
        "outputId": "ab7b5c9c-0e65-4298-e81c-56e42f1ecb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of entities is 14.\n",
            "The number of relations is 55.\n",
            "The number of facts is 1992.\n"
          ]
        }
      ],
      "source": [
        "print(f'The number of entities is {len(entity_2_id)}.')\n",
        "print(f'The number of relations is {len(relation_2_id)}.')\n",
        "print(f'The number of facts is {len(train_data)+len(valid_data)+len(test_data)}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CDwYW4Wn_fu"
      },
      "source": [
        "## **Question 1b**\n",
        "\n",
        "Conduct a brief data analysis, and identify the most popular relations, entities, and briefly describe the dataset structure, i.e., how are entities connected, their types, what does the dataset describe? Etc.\n",
        "\n",
        "---\n",
        "\n",
        "The three most popular entities are 'usa', 'uk', and 'ussr'. The three most popular relationships are 'embassy', 'commonbloc1' (\"common bloc 1\"), and 'timessinceally' (\"times since ally\"). \n",
        "\n",
        "This dataset describes socio-political relationships of a small sample of nations during the Cold War (hence the inclusion of the USSR). Most of the relationships appear to relate to politcal structures and diplomacy. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oljNbYUoCZG"
      },
      "outputs": [],
      "source": [
        "# Putting together train, val, and test set\n",
        "full_facts = list(set(train_data + valid_data + test_data))\n",
        "\n",
        "count_entities = {}\n",
        "count_relations = {}\n",
        "\n",
        "# Compute entity/relation frequencies\n",
        "for f in full_facts:\n",
        "    if f.head in count_entities:\n",
        "        count_entities[f.head] += 1\n",
        "    else:\n",
        "        count_entities[f.head] = 1\n",
        "\n",
        "    if f.tail in count_entities:\n",
        "        count_entities[f.tail] += 1\n",
        "    else:\n",
        "        count_entities[f.tail] = 1\n",
        "\n",
        "    if f.relation in count_relations:\n",
        "        count_relations[f.relation] += 1\n",
        "    else:\n",
        "        count_relations[f.relation] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "vhyLvhNPyJNx",
        "outputId": "ee0a5e8a-3be1-4e92-933a-fe2d2b2d928b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             count\n",
              "usa            514\n",
              "uk             462\n",
              "ussr           331\n",
              "netherlands    313\n",
              "india          302\n",
              "poland         287\n",
              "egypt          284\n",
              "brazil         260\n",
              "china          249\n",
              "israel         243\n",
              "cuba           232\n",
              "indonesia      215\n",
              "jordan         146\n",
              "burma          146"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a44c43e-2eb8-4516-89aa-01e0c0cd5653\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>usa</th>\n",
              "      <td>514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>uk</th>\n",
              "      <td>462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ussr</th>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>netherlands</th>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>india</th>\n",
              "      <td>302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poland</th>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>egypt</th>\n",
              "      <td>284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brazil</th>\n",
              "      <td>260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>china</th>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>israel</th>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cuba</th>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>indonesia</th>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jordan</th>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>burma</th>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a44c43e-2eb8-4516-89aa-01e0c0cd5653')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a44c43e-2eb8-4516-89aa-01e0c0cd5653 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a44c43e-2eb8-4516-89aa-01e0c0cd5653');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Get entity counts\n",
        "ent_df = pd.DataFrame.from_dict(count_entities, orient='index', columns = ['count'])\n",
        "ent_df = ent_df.sort_values('count', ascending=False)\n",
        "ent_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "gqP1HbxAzonI",
        "outputId": "58073260-8dd8-4309-c93b-96729cc53e35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 count\n",
              "embassy            141\n",
              "commonbloc1         97\n",
              "timesinceally       95\n",
              "relintergovorgs     94\n",
              "intergovorgs3       93\n",
              "ngoorgs3            92\n",
              "relngo              91\n",
              "reldiplomacy        87\n",
              "intergovorgs        84\n",
              "independence        78"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b96c0bd8-810d-4ad1-a8da-dd91617cea64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>embassy</th>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>commonbloc1</th>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timesinceally</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relintergovorgs</th>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intergovorgs3</th>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ngoorgs3</th>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relngo</th>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reldiplomacy</th>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intergovorgs</th>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>independence</th>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b96c0bd8-810d-4ad1-a8da-dd91617cea64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b96c0bd8-810d-4ad1-a8da-dd91617cea64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b96c0bd8-810d-4ad1-a8da-dd91617cea64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Get relation counts\n",
        "rel_df = pd.DataFrame.from_dict(count_relations, orient='index', columns = ['count'])\n",
        "rel_df = rel_df.sort_values('count', ascending=False)\n",
        "rel_df.head(10) # only show the first 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VY92MJ6oCsz"
      },
      "source": [
        "## **Establishing, Training, and Evaluating TransE**\n",
        "\n",
        "**(Contains questions 2a and 2b)**\n",
        "\n",
        "Using a machine learning framework of your choice (TensorFlow, PyTorch, etc.), implement the basic TransE model and train it on the \"Nations\". To do this, your implementation should include: \n",
        "1. Entity processing and mapping to embeddings (You can use 100-dimensional embeddings, for instance, but the choice of model size is not critical. It just should be reasonably sized)\n",
        "2. Scoring function and loss (My recommendation for loss is negative sampling loss (from the RotatE paper). I also suggest not using the self-adversarial parameter alpha, i.e., setting it to 0, for a start)\n",
        "3. (Uniform) Negative sampling and training loop\n",
        "4. Evaluation metrics (mean rank, mean reciprocal rank, Hits@K)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-gdleWv_Zba"
      },
      "source": [
        "**TransE Notes**\n",
        "\n",
        "- Underlying assumption of TransE: \"In TransE, relationships are represented as translations in the embedding space: if (h, l, t) holds, then the embedding of the tail entity t should be close to the embedding of the head entity h plus some vector that depends on the relationship l. Our approach relies on a reduced set of parameters as it learns only one low-dimensional vector for each entity and each relationship.\" --> improvement over other multi-relational models that are complex and thus require lots of computing power and overfit and often barely do better than a simple linear model\n",
        "- Why does this work? heirarchy is super common in knowledge bases (like our \"Nations\" dataset)\n",
        "- Research suggests that entities of different types could also be represented by translations in the embedding space (I think embedding space is the dimension of the vectors that we allow for these translations --> this dimension can be represented by the hyperparameter k)\n",
        "- Goal is vector embedding for h + l is close to t if (h, l, t) is a triple and farther otherwise (h, l, and t are vectors once embedded) --> \"t should be a nearest neighbor of h + l\"\n",
        "- \"L2-norm of the embeddings of the entities is 1\" --> no regularization for relations except at initialization--> regularize entities to prevent driving up vector size to drive down loss/massively overfit\n",
        "- \"At each main iteration of the algorithm, the embedding vectors of the entities are first normalized\"\n",
        "- Full algorithm description: \". All embeddings for entities and\n",
        "relationships are first initialized following the random procedure proposed in [4]. At each main\n",
        "iteration of the algorithm, the embedding vectors of the entities are first normalized. Then, a small\n",
        "set of triplets is sampled from the training set, and will serve as the training triplets of the minibatch.\n",
        "For each such triplet, we then sample a single corrupted triplet. The parameters are then updated by\n",
        "taking a gradient step with constant learning rate. The algorithm is stopped based on its performance\n",
        "on a validation set\"\n",
        "- distance function can be squared Euclidean distance function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFd2vyXEQNwg"
      },
      "outputs": [],
      "source": [
        "# Functiont to normalize an array in-place\n",
        "def normalize_vector(my_array):\n",
        "    norm = torch.linalg.vector_norm(my_array)\n",
        "    my_array /= norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVXsd92xPZC3"
      },
      "outputs": [],
      "source": [
        "# Function to intialize normal vectors for entity/relation embeddings\n",
        "def initialize_normal_vectors(d, items):\n",
        "    my_list = []\n",
        "\n",
        "    for i in items:\n",
        "        new_array = torch.FloatTensor(d).uniform_(-6/d**(1/2), 6/d**(1/2)) # Generate randomized vector from uniform distribution\n",
        "        normalize_vector(new_array) # Normalize vector\n",
        "        new_array.requires_grad_()\n",
        "        my_list.append(new_array)\n",
        "\n",
        "    return my_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d81ohkwD8XA3"
      },
      "outputs": [],
      "source": [
        "# Generate a list of negative facts by passing in all possible entities, a fact to corrupt, and a list of all true facts\n",
        "def get_list_of_negative_facts(all_entities, a_fact, all_facts):\n",
        "    all_corrupted_facts = []\n",
        "    all_facts_set = set(all_facts)\n",
        "    for a in all_entities:\n",
        "        \n",
        "        # Change just the head and add if that fact isn't in the set of true facts\n",
        "        if a != a_fact.head:\n",
        "            new_fact = Fact(a, a_fact.relation, a_fact.tail)\n",
        "            if new_fact not in all_facts_set: # checking that the fact isn't in ANY part of the KG\n",
        "                all_corrupted_facts.append(new_fact)\n",
        "                \n",
        "        # Change just the tail and add if that fact isn't in the set of true facts\n",
        "        if a != a_fact.tail:\n",
        "            new_fact = Fact(a_fact.head, a_fact.relation, a)\n",
        "            if new_fact not in all_facts_set:\n",
        "                all_corrupted_facts.append(new_fact)\n",
        "      \n",
        "    return all_corrupted_facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rNNmuaXLDt8"
      },
      "outputs": [],
      "source": [
        "# Dissimilarity measure - L2 norm (||h+r-t||_2)\n",
        "def score_L2(h, r, t):\n",
        "    return torch.linalg.vector_norm(h+r-t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW5bst3nD6al"
      },
      "outputs": [],
      "source": [
        "# Create positive/negative fact pairs - one neg sampled for each pos, as descibed in paper\n",
        "def get_pos_neg_fact_pairs(all_entities, all_facts):\n",
        "    a_set = set()\n",
        "    for a in all_facts:\n",
        "        neg_fact = random.choice(get_list_of_negative_facts(all_entities, a, all_facts))\n",
        "        a_set.add((a, neg_fact))\n",
        "    return a_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kSBELh8D6al"
      },
      "outputs": [],
      "source": [
        "# Compute TransE loss, as described in original paper\n",
        "def transe_loss(t_batch, margin, ent_2_vec, rel_2_vec, entity_embeddings, relation_embeddings):\n",
        "    total_loss = 0\n",
        "    for t in t_batch:\n",
        "        pos_fact = t[0]\n",
        "        neg_fact = t[1]\n",
        "        \n",
        "        pos_fact_score = score_L2(entity_embeddings[ent_2_vec[pos_fact.head]], \n",
        "                                  relation_embeddings[rel_2_vec[pos_fact.relation]], \n",
        "                                  entity_embeddings[ent_2_vec[pos_fact.tail]])\n",
        "        neg_fact_score = score_L2(entity_embeddings[ent_2_vec[neg_fact.head]], \n",
        "                                  relation_embeddings[rel_2_vec[neg_fact.relation]], \n",
        "                                  entity_embeddings[ent_2_vec[neg_fact.tail]])\n",
        "\n",
        "        total_loss += max(0, margin+pos_fact_score-neg_fact_score)\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJxkPXlRD6am"
      },
      "outputs": [],
      "source": [
        "# Get rank of the target entity in a numpy array of embedding scores\n",
        "def get_rank(a_list, an_index):\n",
        "    temp = a_list.argsort()\n",
        "    rank = np.empty_like(temp)\n",
        "    rank[temp] = np.arange(len(a_list))\n",
        "    return rank[an_index]+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2HSjb_pD6am"
      },
      "outputs": [],
      "source": [
        "# Get rank of observed heads/tails against corrupted alternatives\n",
        "def create_rank_arrays(model, dataset):\n",
        "    entity_embeddings = model[0]\n",
        "    relation_embeddings = model[1]\n",
        "    ent_2_vec = model[2]\n",
        "    rel_2_vec = model[3]\n",
        "\n",
        "    head_rank_list = np.zeros(len(dataset))\n",
        "    tail_rank_list = np.zeros(len(dataset))\n",
        "    for idxv, v in enumerate(valid_data):\n",
        "        head_embedding_index = ent_2_vec.get(v.head)\n",
        "        relation_embedding = relation_embeddings[rel_2_vec.get(v.relation)]\n",
        "        tail_embedding_index = ent_2_vec.get(v.tail)\n",
        "\n",
        "        heads_corrupted = np.zeros(len(entity_embeddings))\n",
        "        tails_corrupted = np.zeros(len(entity_embeddings))\n",
        "        for idxe, e in enumerate(entity_embeddings):\n",
        "            heads_corrupted[idxe] = score_L2(e, relation_embedding, entity_embeddings[tail_embedding_index]).item()\n",
        "            tails_corrupted[idxe] = score_L2(entity_embeddings[head_embedding_index], relation_embedding, e).item()\n",
        "\n",
        "        head_rank_list[idxv] = get_rank(heads_corrupted, head_embedding_index)\n",
        "        tail_rank_list[idxv] = get_rank(tails_corrupted, tail_embedding_index)\n",
        "    \n",
        "    return head_rank_list, tail_rank_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean rank metric\n",
        "def compute_mean_rank(head_rank_list, tail_rank_list, dataset_length):\n",
        "    return (sum(head_rank_list)+sum(tail_rank_list))/(2*dataset_length)"
      ],
      "metadata": {
        "id": "cLeKs2NgXCrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean reciprocal rank metric\n",
        "def compute_mean_reciprocal_rank(head_rank_list, tail_rank_list, dataset_length):\n",
        "    return (np.sum(1/head_rank_list)+np.sum(1/tail_rank_list))/(2*dataset_length)"
      ],
      "metadata": {
        "id": "K0sAYAMVXPYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hits@k metric\n",
        "def compute_hits_at_k(head_rank_list, tail_rank_list, k, dataset_length):\n",
        "    return (np.count_nonzero(head_rank_list <= k)+np.count_nonzero(tail_rank_list <= k))/(2*dataset_length) * 100"
      ],
      "metadata": {
        "id": "P-KLSv9cXXYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate a model (entity/relation embeddings) using all 3 metrics\n",
        "def eval_model(model, dataset, k):\n",
        "  head_rank_list, tail_rank_list = create_rank_arrays(model, valid_data)\n",
        "\n",
        "  return (compute_mean_rank(head_rank_list, tail_rank_list, len(dataset)), \n",
        "          compute_mean_reciprocal_rank(head_rank_list, tail_rank_list, len(dataset)), \n",
        "          compute_hits_at_k(head_rank_list, tail_rank_list, k, len(dataset)))"
      ],
      "metadata": {
        "id": "wLmcpE0rWakh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback to perform early stopping\n",
        "#   - if current val mean rank isn't better than any of last \"how_many_to_check\" epochs, stop the training\n",
        "def early_stopping_callback(model, dataset, k, mr_array, how_many_to_check):\n",
        "    head_rank_list, tail_rank_list = create_rank_arrays(model, dataset)\n",
        "\n",
        "    cur_mr = compute_mean_rank(head_rank_list, tail_rank_list, len(dataset))\n",
        "    mr_array.append(cur_mr)\n",
        "    if len(mr_array) > how_many_to_check + 1:\n",
        "        recent_epoch_mrs = np.array(mr_array[-(how_many_to_check+1) : -1])\n",
        "\n",
        "        if np.count_nonzero(recent_epoch_mrs > cur_mr) > 0:\n",
        "            return False\n",
        "        print('Final validation mean rank: ', cur_mr)\n",
        "        return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "72tDWQ6-biS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0hU_l-RD6al"
      },
      "outputs": [],
      "source": [
        "# Train the TransE model - output is entity/relation embeddings in k-dimensional vector space\n",
        "def train(entities, relations, facts, d, margin, epochs, batch_size, learning_rate, valid_dataset=None, k=5, how_many_to_check=5, verbose=True):\n",
        "    entity_embeddings = initialize_normal_vectors(d, entities)\n",
        "    relation_embeddings = initialize_normal_vectors(d, relations)\n",
        "    \n",
        "    ent_2_vec = {}\n",
        "    rel_2_vec = {}\n",
        "\n",
        "    # Create a dictionary mapping for easy embedding lookup for entities\n",
        "    for e in range(len(entities)):\n",
        "        ent_2_vec[entities[e]] = e\n",
        "\n",
        "    # Create a dictionary mapping for easy embedding lookup for relations\n",
        "    for r in range(len(relations)):\n",
        "        rel_2_vec[relations[r]] = r\n",
        "    \n",
        "    mr_array = []\n",
        "\n",
        "    # Define our optimizer to use stochastic gradient descent\n",
        "    optimizer = optim.SGD(entity_embeddings + relation_embeddings, lr = learning_rate)\n",
        "    \n",
        "    for e in range(epochs):\n",
        "        if e%5 == 0 and verbose:\n",
        "            print('Epoch:', e)\n",
        "        for i in range(int(len(facts) / batch_size)):\n",
        "\n",
        "            # Select a batch from all facts\n",
        "            fact_sample = random.sample(facts, batch_size)\n",
        "            t_batch = get_pos_neg_fact_pairs(entities, fact_sample)\n",
        "            \n",
        "            # Only normalize the entity vector embeddings\n",
        "            with torch.no_grad():\n",
        "                for an_ent in entity_embeddings:\n",
        "                    normalize_vector(an_ent)\n",
        "            \n",
        "            # Compute transe loss\n",
        "            loss = transe_loss(t_batch, margin, ent_2_vec, rel_2_vec, entity_embeddings, relation_embeddings)    \n",
        "            \n",
        "            # Update embeddings\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluate model at end of epoch\n",
        "        if valid_data is not None:\n",
        "            model = entity_embeddings, relation_embeddings, ent_2_vec, rel_2_vec\n",
        "            if early_stopping_callback(model, valid_dataset, k, mr_array, how_many_to_check):\n",
        "                print('Stopping at epoch:', e)\n",
        "                break\n",
        "          \n",
        "    return entity_embeddings, relation_embeddings, ent_2_vec, rel_2_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAEcEUaxD6am",
        "outputId": "3b59785d-d057-48c4-cd16-c9121bf719da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training set:  1592\n",
            "Epoch: 0\n",
            "Epoch: 5\n",
            "Epoch: 10\n",
            "Epoch: 15\n",
            "Epoch: 20\n",
            "Epoch: 25\n",
            "Epoch: 30\n",
            "Final validation mean rank:  6.922110552763819\n",
            "Stopping at epoch: 34\n"
          ]
        }
      ],
      "source": [
        "# Check model training w/arbitrary-chosen hyperparams\n",
        "entities = list(entity_2_id.keys())\n",
        "relations = list(relation_2_id.keys())\n",
        "d = 100\n",
        "margin = 0.5\n",
        "epochs = 1000\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "k = 5\n",
        "validation_num_to_check = 5\n",
        "\n",
        "print('Length of training set: ', len(train_data))\n",
        "model = train(entities, relations, train_data, d, margin, epochs, batch_size, learning_rate, valid_data, k, validation_num_to_check, verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Formal hyperparamter tuning using same grid-search values as TransE paper (we added 100 for latent dim)\n",
        "lr_list = [0.001, 0.01, 0.1]\n",
        "margin_list = [1, 2, 10]\n",
        "latent_dim = [20, 50, 100]\n",
        "all_models = {}\n",
        "\n",
        "for lr in lr_list:\n",
        "    for m in margin_list:\n",
        "        for ld in latent_dim:\n",
        "            print('Learning rate:', lr, 'Margin:', m, 'Latent dimension:', ld)\n",
        "            all_models[(lr, m, ld)] = train(entities, relations, train_data, ld, m, epochs, batch_size, lr, valid_data, k, validation_num_to_check, False)"
      ],
      "metadata": {
        "id": "2Vh6QqYeGtpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333aca83-c0de-48b3-ddf2-688bcaab91f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.001 Margin: 1 Latent dimension: 20\n",
            "Final validation mean rank:  6.71356783919598\n",
            "Stopping at epoch: 68\n",
            "Learning rate: 0.001 Margin: 1 Latent dimension: 50\n",
            "Final validation mean rank:  6.665829145728643\n",
            "Stopping at epoch: 49\n",
            "Learning rate: 0.001 Margin: 1 Latent dimension: 100\n",
            "Final validation mean rank:  6.673366834170854\n",
            "Stopping at epoch: 57\n",
            "Learning rate: 0.001 Margin: 2 Latent dimension: 20\n",
            "Final validation mean rank:  6.902010050251256\n",
            "Stopping at epoch: 46\n",
            "Learning rate: 0.001 Margin: 2 Latent dimension: 50\n",
            "Final validation mean rank:  6.9045226130653266\n",
            "Stopping at epoch: 47\n",
            "Learning rate: 0.001 Margin: 2 Latent dimension: 100\n",
            "Final validation mean rank:  6.768844221105527\n",
            "Stopping at epoch: 29\n",
            "Learning rate: 0.001 Margin: 10 Latent dimension: 20\n",
            "Final validation mean rank:  6.85678391959799\n",
            "Stopping at epoch: 49\n",
            "Learning rate: 0.001 Margin: 10 Latent dimension: 50\n",
            "Final validation mean rank:  6.751256281407035\n",
            "Stopping at epoch: 67\n",
            "Learning rate: 0.001 Margin: 10 Latent dimension: 100\n",
            "Final validation mean rank:  6.8542713567839195\n",
            "Stopping at epoch: 41\n",
            "Learning rate: 0.01 Margin: 1 Latent dimension: 20\n",
            "Final validation mean rank:  7.010050251256281\n",
            "Stopping at epoch: 14\n",
            "Learning rate: 0.01 Margin: 1 Latent dimension: 50\n",
            "Final validation mean rank:  6.886934673366834\n",
            "Stopping at epoch: 12\n",
            "Learning rate: 0.01 Margin: 1 Latent dimension: 100\n",
            "Final validation mean rank:  6.763819095477387\n",
            "Stopping at epoch: 17\n",
            "Learning rate: 0.01 Margin: 2 Latent dimension: 20\n",
            "Final validation mean rank:  6.763819095477387\n",
            "Stopping at epoch: 12\n",
            "Learning rate: 0.01 Margin: 2 Latent dimension: 50\n",
            "Final validation mean rank:  6.934673366834171\n",
            "Stopping at epoch: 8\n",
            "Learning rate: 0.01 Margin: 2 Latent dimension: 100\n",
            "Final validation mean rank:  6.881909547738694\n",
            "Stopping at epoch: 11\n",
            "Learning rate: 0.01 Margin: 10 Latent dimension: 20\n",
            "Final validation mean rank:  6.846733668341709\n",
            "Stopping at epoch: 16\n",
            "Learning rate: 0.01 Margin: 10 Latent dimension: 50\n",
            "Final validation mean rank:  6.809045226130653\n",
            "Stopping at epoch: 9\n",
            "Learning rate: 0.01 Margin: 10 Latent dimension: 100\n",
            "Final validation mean rank:  6.889447236180905\n",
            "Stopping at epoch: 6\n",
            "Learning rate: 0.1 Margin: 1 Latent dimension: 20\n",
            "Final validation mean rank:  7.077889447236181\n",
            "Stopping at epoch: 12\n",
            "Learning rate: 0.1 Margin: 1 Latent dimension: 50\n",
            "Final validation mean rank:  7.065326633165829\n",
            "Stopping at epoch: 10\n",
            "Learning rate: 0.1 Margin: 1 Latent dimension: 100\n",
            "Final validation mean rank:  7.331658291457287\n",
            "Stopping at epoch: 8\n",
            "Learning rate: 0.1 Margin: 2 Latent dimension: 20\n",
            "Final validation mean rank:  7.454773869346734\n",
            "Stopping at epoch: 6\n",
            "Learning rate: 0.1 Margin: 2 Latent dimension: 50\n",
            "Final validation mean rank:  7.062814070351759\n",
            "Stopping at epoch: 11\n",
            "Learning rate: 0.1 Margin: 2 Latent dimension: 100\n",
            "Final validation mean rank:  7.309045226130653\n",
            "Stopping at epoch: 10\n",
            "Learning rate: 0.1 Margin: 10 Latent dimension: 20\n",
            "Final validation mean rank:  7.241206030150754\n",
            "Stopping at epoch: 14\n",
            "Learning rate: 0.1 Margin: 10 Latent dimension: 50\n",
            "Final validation mean rank:  7.316582914572864\n",
            "Stopping at epoch: 9\n",
            "Learning rate: 0.1 Margin: 10 Latent dimension: 100\n",
            "Final validation mean rank:  7.077889447236181\n",
            "Stopping at epoch: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating test performance for all saved models from hyperparam tuning\n",
        "for key in all_models.keys():\n",
        "  print(key)\n",
        "  cur_model = all_models.get(key)\n",
        "  eval = np.round(eval_model(cur_model, test_data, k), 2)\n",
        "  print('Average rank:', eval[0])\n",
        "  print('Mean reciprocal rank:', eval[1])\n",
        "  print(f'Hits @ {k}:', str(eval[2])+'%')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7607AKXaMVk6",
        "outputId": "67cb2845-ed91-44ff-d649-cb75b8c715b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.001, 1, 20)\n",
            "Average rank: 6.65\n",
            "Mean reciprocal rank: 0.23\n",
            "Hits @ 5: 42.04%\n",
            "\n",
            "(0.001, 1, 50)\n",
            "Average rank: 6.6\n",
            "Mean reciprocal rank: 0.23\n",
            "Hits @ 5: 41.79%\n",
            "\n",
            "(0.001, 1, 100)\n",
            "Average rank: 6.61\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 45.02%\n",
            "\n",
            "(0.001, 2, 20)\n",
            "Average rank: 6.83\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 39.8%\n",
            "\n",
            "(0.001, 2, 50)\n",
            "Average rank: 6.84\n",
            "Mean reciprocal rank: 0.21\n",
            "Hits @ 5: 39.05%\n",
            "\n",
            "(0.001, 2, 100)\n",
            "Average rank: 6.7\n",
            "Mean reciprocal rank: 0.2\n",
            "Hits @ 5: 40.55%\n",
            "\n",
            "(0.001, 10, 20)\n",
            "Average rank: 6.79\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 40.3%\n",
            "\n",
            "(0.001, 10, 50)\n",
            "Average rank: 6.68\n",
            "Mean reciprocal rank: 0.21\n",
            "Hits @ 5: 42.04%\n",
            "\n",
            "(0.001, 10, 100)\n",
            "Average rank: 6.79\n",
            "Mean reciprocal rank: 0.21\n",
            "Hits @ 5: 43.03%\n",
            "\n",
            "(0.01, 1, 20)\n",
            "Average rank: 6.94\n",
            "Mean reciprocal rank: 0.2\n",
            "Hits @ 5: 36.32%\n",
            "\n",
            "(0.01, 1, 50)\n",
            "Average rank: 6.82\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 40.55%\n",
            "\n",
            "(0.01, 1, 100)\n",
            "Average rank: 6.7\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 41.04%\n",
            "\n",
            "(0.01, 2, 20)\n",
            "Average rank: 6.7\n",
            "Mean reciprocal rank: 0.23\n",
            "Hits @ 5: 40.8%\n",
            "\n",
            "(0.01, 2, 50)\n",
            "Average rank: 6.87\n",
            "Mean reciprocal rank: 0.21\n",
            "Hits @ 5: 39.8%\n",
            "\n",
            "(0.01, 2, 100)\n",
            "Average rank: 6.81\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 38.56%\n",
            "\n",
            "(0.01, 10, 20)\n",
            "Average rank: 6.78\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 39.3%\n",
            "\n",
            "(0.01, 10, 50)\n",
            "Average rank: 6.74\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 38.81%\n",
            "\n",
            "(0.01, 10, 100)\n",
            "Average rank: 6.82\n",
            "Mean reciprocal rank: 0.21\n",
            "Hits @ 5: 38.81%\n",
            "\n",
            "(0.1, 1, 20)\n",
            "Average rank: 7.01\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 39.8%\n",
            "\n",
            "(0.1, 1, 50)\n",
            "Average rank: 7.0\n",
            "Mean reciprocal rank: 0.24\n",
            "Hits @ 5: 39.3%\n",
            "\n",
            "(0.1, 1, 100)\n",
            "Average rank: 7.26\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 35.57%\n",
            "\n",
            "(0.1, 2, 20)\n",
            "Average rank: 7.38\n",
            "Mean reciprocal rank: 0.21\n",
            "Hits @ 5: 36.57%\n",
            "\n",
            "(0.1, 2, 50)\n",
            "Average rank: 6.99\n",
            "Mean reciprocal rank: 0.23\n",
            "Hits @ 5: 38.81%\n",
            "\n",
            "(0.1, 2, 100)\n",
            "Average rank: 7.24\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits @ 5: 37.06%\n",
            "\n",
            "(0.1, 10, 20)\n",
            "Average rank: 7.17\n",
            "Mean reciprocal rank: 0.24\n",
            "Hits @ 5: 36.57%\n",
            "\n",
            "(0.1, 10, 50)\n",
            "Average rank: 7.24\n",
            "Mean reciprocal rank: 0.23\n",
            "Hits @ 5: 36.57%\n",
            "\n",
            "(0.1, 10, 100)\n",
            "Average rank: 7.01\n",
            "Mean reciprocal rank: 0.24\n",
            "Hits @ 5: 40.3%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "kXv8kA_HD6am"
      },
      "source": [
        "### **Evaluation & Analysis**\n",
        "\"Evaluation protocol For evaluation, we use the same ranking procedure as in [3]. For each test triplet, the head is removed and replaced by each of the entities of the dictionary in turn. Dissimilarities (or energies) of those corrupted triplets are first computed by the models and then sorted by ascending order; the rank of the correct entity is finally stored. This whole procedure is repeated while removing the tail instead of the head. We report the mean of those predicted ranks and the hits@10, i.e. the proportion of correct entities ranked in the top 10.\"\n",
        "\n",
        "\"These metrics are indicative but can be flawed when some corrupted triplets end up being valid\n",
        "ones, from the training set for instance. \"\n",
        "\n",
        "This is different in the paper from the class slide implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 2a**\n",
        "How does TransE perform on this task?\n",
        "\n",
        "---\n",
        "\n",
        "The below cells show TransE's test set performance. The trained TransE *substantially* better than a random embeddings (the cell below), which shows that the model did indeed learn during training, even if the performance isn't stellar. It's possible that one element constraining performance is the negative saampling scheme from the TransE paper, which is very simple--only one corrupted fact is used for each real fact, which is substantially less informative than more sophisticated sampling methods.\n",
        "\n",
        "How can we explain the facts that TransE can and cannot predict well? \n",
        "- Poorly: from class, we know that TransE cannot do well on symmetric relations and this dataset has many realtions with inherent symmetry (e.g. countries are allies both ways). \n",
        "- Well: being able to embody a composition pattern as described in class seems intuitively good, as approximately transitivity seems prevalent in this dataset.\n",
        "- Hypothesis: had some difficulties with properly capturing the political allies and enemies in this dataset, which seems to focus on cold war poltical relations (see for example embassy relations). This may have to do with the inference patterns that TransE can and cannot capture (mentioned above).\n",
        "  - Difficult to say this for sure, since we're not super familiar with cold war era political relations."
      ],
      "metadata": {
        "id": "Xvw5geDNBYKB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bl_F3FhD6am",
        "outputId": "5aa71de3-26be-4730-9e84-2b423fa6c084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average rank: 6.61\n",
            "Mean reciprocal rank: 0.22\n",
            "Hits@5: 45.02%\n"
          ]
        }
      ],
      "source": [
        "# Compute mean rank, mean reciprocal rank, and hits@k on the test set\n",
        "best_model = all_models.get((0.001, 1, 100)) # getting the best model from the tuning process\n",
        "\n",
        "eval = np.round(eval_model(best_model, test_data, k), 2)\n",
        "print('Average rank:', eval[0])\n",
        "print('Mean reciprocal rank:', eval[1])\n",
        "print(f'Hits@{k}:', str(eval[2])+'%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the performance of a randomly-initialized model... for comparison against trained model!\n",
        "mr = []\n",
        "mrr = []\n",
        "hak = []\n",
        "\n",
        "for i in range(20): # averaging over 20 random initializations for embeddings vectors\n",
        "  random_model = train(entities, relations, train_data, 100, 1, 0, batch_size, 0.001, test_data, k, validation_num_to_check, False) # zero epochs == random embeddings\n",
        "  eval = np.round(eval_model(random_model, test_data, k), 2)\n",
        "  mr.append(eval[0])\n",
        "  mrr.append(eval[1])\n",
        "  hak.append(eval[2])\n",
        "\n",
        "print('Average rank:', round(np.mean(mr), 2))\n",
        "print('Mean reciprocal rank:', round(np.mean(mrr), 2))\n",
        "print(f'Hits@{k}: {round(np.mean(hak), 2)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwO_oo1ybo4P",
        "outputId": "712fbc4d-a288-4139-c306-becf34187ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average rank: 7.92\n",
            "Mean reciprocal rank: 0.17\n",
            "Hits@5: 30.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Return a list of facts that the trained model performed well on under head and tail corruption\n",
        "def get_good_facts(model, dataset, how_good):\n",
        "    head_rank_list, tail_rank_list = create_rank_arrays(model, dataset)\n",
        "    mask_head = head_rank_list < how_good\n",
        "    mask_tail = tail_rank_list < how_good\n",
        "    mask = mask_head & mask_tail\n",
        "    dataset_np = np.array(dataset)\n",
        "    \n",
        "    return dataset_np[mask.nonzero()]"
      ],
      "metadata": {
        "id": "QTYxcCTHknsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return a list of facts that the trained model performed poorly on under head and tail corruption\n",
        "def get_bad_facts(model, dataset, how_bad, entities):\n",
        "    head_rank_list, tail_rank_list = create_rank_arrays(model, dataset)\n",
        "    mask_head = head_rank_list > (len(entities) - how_bad)\n",
        "    mask_tail = tail_rank_list > (len(entities) - how_bad)\n",
        "    mask = mask_head & mask_tail\n",
        "    dataset_np = np.array(dataset)\n",
        "    \n",
        "    return dataset_np[mask.nonzero()]"
      ],
      "metadata": {
        "id": "E6mPhl06-R25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find facts the model did well and poorly on in the test set\n",
        "how_good = 4\n",
        "how_bad = 4\n",
        "\n",
        "print('List of test data facts model did well on: ')\n",
        "[print(i) for i in get_good_facts(best_model, test_data, how_good)]\n",
        "print()\n",
        "print()\n",
        "\n",
        "print('List of test data facts model did poorly on: ')\n",
        "[print(i) for i in get_bad_facts(best_model, test_data, how_bad, entities)]\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln2PJ_hskfY8",
        "outputId": "07f3be3e-d3d6-4c5d-e1c1-f57633abff92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of test data facts model did well on: \n",
            "israel commonbloc1 cuba\n",
            "usa independence china\n",
            "burma relintergovorgs usa\n",
            "india commonbloc1 poland\n",
            "china relexports cuba\n",
            "usa unweightedunvote israel\n",
            "ussr relbooktranslations usa\n",
            "uk tourism3 egypt\n",
            "poland reltreaties ussr\n",
            "israel intergovorgs3 egypt\n",
            "indonesia reldiplomacy egypt\n",
            "egypt embassy cuba\n",
            "jordan relintergovorgs poland\n",
            "israel relngo india\n",
            "egypt reldiplomacy usa\n",
            "indonesia ngoorgs3 india\n",
            "cuba timesincewar usa\n",
            "indonesia relngo usa\n",
            "netherlands relexportbooks uk\n",
            "burma ngoorgs3 israel\n",
            "usa embassy brazil\n",
            "netherlands commonbloc2 uk\n",
            "burma relintergovorgs egypt\n",
            "egypt commonbloc1 brazil\n",
            "india intergovorgs burma\n",
            "indonesia commonbloc1 netherlands\n",
            "brazil intergovorgs poland\n",
            "jordan relngo usa\n",
            "israel commonbloc1 netherlands\n",
            "jordan ngoorgs3 netherlands\n",
            "\n",
            "\n",
            "List of test data facts model did poorly on: \n",
            "egypt embassy uk\n",
            "indonesia violentactions uk\n",
            "usa officialvisits indonesia\n",
            "china officialvisits indonesia\n",
            "uk intergovorgs3 brazil\n",
            "poland reldiplomacy cuba\n",
            "indonesia embassy burma\n",
            "israel relngo usa\n",
            "usa accusation cuba\n",
            "indonesia commonbloc2 burma\n",
            "cuba officialvisits china\n",
            "cuba tourism3 ussr\n",
            "poland reldiplomacy india\n",
            "usa timesinceally netherlands\n",
            "egypt commonbloc2 india\n",
            "usa blockpositionindex ussr\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 2b**\n",
        "\n",
        "Hyperparameter tuning is performed above. In the end, the best choice of hyperparameters was a learning rate of 0.001, a margin of $\\gamma=$ 1, and an embedding dimension of 100 (slightly higher performance, as measured by hits@k, than alternative embedding dimensions).\n",
        "\n",
        "- Margin: the model doesn't seem too sensitive to the choice of margin--we tried [1,2,10] and model performance didn't seem to generally be directly affected by this choice.\n",
        "- Learning rate: 0.001 and 0.01 seemed to work substantially better than 0.1... mean rank deteriorates when `lr=0.1`.\n",
        "- Embedding dimensionality: hits@k often improved when increasing embedding dimensionality, but mean rank is relatively consistent across choices of these hyperparameters."
      ],
      "metadata": {
        "id": "7OId7LNn1mww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Misc Testing**\n",
        "\n",
        "Code below is not for the model but for our own benefit. "
      ],
      "metadata": {
        "id": "RHQzX6nAacGc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atPWg2T8D6am",
        "outputId": "c8e274d9-bd22-467c-b5ef-2dd56fbb2462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "4\n",
            "1.8928571428571428\n"
          ]
        }
      ],
      "source": [
        "hi = np.zeros(4)\n",
        "hi[0] = 4\n",
        "hi[1] = 2\n",
        "hi[2] = 7\n",
        "hi[3] = 1\n",
        "\n",
        "print(get_rank(hi, 3))\n",
        "print(np.count_nonzero(hi < 10))\n",
        "print(np.sum(1/hi))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([1, 0, 1]) & np.array([1, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMJQ10BamarA",
        "outputId": "549b186b-eeeb-4a7b-8310-dda19fa1846f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE_5OyL4qHS-"
      },
      "source": [
        "#### Sources\n",
        "1. https://stackoverflow.com/questions/12021730/can-pandas-handle-variable-length-whitespace-as-column-delimiters\n",
        "2. https://www.geeksforgeeks.org/how-to-read-text-files-with-pandas/#:~:text=We%20can%20read%20data%20from,of%20a%20comma%20by%20default\n",
        "3. https://realpython.com/pandas-sort-python/#:~:text=To%20sort%20the%20DataFrame%20based,not%20modify%20the%20original%20DataFrame.\n",
        "4. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html\n",
        "5. https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
        "6. https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
        "7. [Paper describing TransE](https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EENwGQ2UD6an"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fmLMG_TunXvN",
        "FDJaBxlqn8JX",
        "7CDwYW4Wn_fu",
        "2VY92MJ6oCsz",
        "RHQzX6nAacGc"
      ],
      "name": "Assignment1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}